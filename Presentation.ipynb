{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab041a51-ed34-41c5-990d-c3c71887ca07",
   "metadata": {},
   "source": [
    "# Optical Character Recognition (OCR) on Mathematical Expression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4132553-4026-47f4-9e01-a3b8673169ba",
   "metadata": {},
   "source": [
    "Optical Character Recognition refers to extracting written texts from digital images into machine readable text. OCR can be used on printed, handwritten, and natural scene texts [3]. In this project, our goal is to extracting each single math symbol from mathematical expressions and ouputting the corresponding latex codes. For example, for the expression cos(x)=0, we have the collection of latex codes {\\cos, x, (, ), =, 0}."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301a1f6d-42de-4d8e-a17b-7bde6f7bd296",
   "metadata": {},
   "source": [
    "Our input data are the collection of four datasets: \n",
    "* expressmatch: University of Sao Paulo, \n",
    "* MathBrush: University of Waterloo, \n",
    "* KAIST: KAIST lab, \n",
    "* HAMEX: University of Nantes. \n",
    "\n",
    "from CROHME version 2013, the 2013 Competition on Recognition of Online Handwritten Mathematical Expressions [2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f24f3fe-e316-4318-9efd-b35a14baab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "from os import listdir as ls\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pickleshare\n",
    "import sklearn\n",
    "import skimage\n",
    "from skimage.draw import line\n",
    "from skimage.morphology import thin\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import xml.etree.ElementTree as ET\n",
    "import argparse\n",
    "import cv2\n",
    "import one_hot\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e735f8cd-b2df-44ee-844f-8d9c48d17f8d",
   "metadata": {},
   "source": [
    "# Phase I: Build our Mathematical Expression Recognition Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4a6a12-a283-45f6-8dbd-f4849dc19276",
   "metadata": {},
   "source": [
    "The original data are in inkml files, we first perform the following steps using python files in terminal [5]: \n",
    "* Extract trace groups from inkml files.\n",
    "* Convert extracted trace groups into images. Images are square shaped bitmaps with only black (value 0) and white (value 1) pixels. Black color denotes patterns (ROI).\n",
    "* Label those images according to inkml files.\n",
    "* Flatten images to one-dimensional vectors.\n",
    "* Convert labels to one-hot format.\n",
    "* Dump training and testing sets separately into outputs folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9cdc3c-b3e2-45ec-a408-78d069f642dc",
   "metadata": {},
   "source": [
    "Since the dataset is imbalanced, we then balance the dataset using python file balance.py on terminal [5].\n",
    "* command line argument: python balance.py -b 28 -ub 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec2e81c3-04a6-4cd0-a494-f3a6f1148846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CROHME2013_data',\n",
       " 'index.html',\n",
       " 'CROHME_papers',\n",
       " 'CROHME2012_data',\n",
       " 'evaluationTools',\n",
       " 'ParticipantsResults2012',\n",
       " 'readme.txt',\n",
       " 'CROHME2011_data',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/home/DAVIDSON/mawang1/Workspace/CSC381/implementation-project-dl-f22-hueynataliemaureenilina/'\n",
    "data_dir = os.path.join(path, 'CROHME_full_v2/')\n",
    "ls(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42ebdd88-96ed-4525-b740-52688fb2332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = path+'outputs/test/'\n",
    "train_path = path+'outputs/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48dd0766-9f1e-44da-b281-af28004b7419",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle(train_path+'train.pickle', compression='infer')\n",
    "test_data = pd.read_pickle(test_path+'test.pickle', compression='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1448aaec-3ea5-4df2-a404-4d13d03ac7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310899</th>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310900</th>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310901</th>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310902</th>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.991...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310903</th>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.290...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310904 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 features  \\\n",
       "0       [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "1       [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "2       [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "3       [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, ...   \n",
       "...                                                   ...   \n",
       "310899  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "310900  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "310901  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "310902  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.991...   \n",
       "310903  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.290...   \n",
       "\n",
       "                                                    label  \n",
       "0       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n",
       "...                                                   ...  \n",
       "310899  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "310900  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "310901  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "310902  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "310903  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[310904 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = pd.DataFrame(train_data)\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14fc567e-017a-4cd5-b118-d5409b5fbd96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5494</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5495</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5496</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5497</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5498</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5499 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               features  \\\n",
       "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1     [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "5494  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...   \n",
       "5495  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...   \n",
       "5496  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, ...   \n",
       "5497  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, ...   \n",
       "5498  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                                  label  \n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "3     [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                 ...  \n",
       "5494  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5495  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "5496  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5497  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5498  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[5499 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds = pd.DataFrame(test_data)\n",
    "test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f45fa01-74b6-45db-8688-c443cacf64b2",
   "metadata": {},
   "source": [
    "Our Mathematical Expression has 310,904 training data and 5499 testing data. For extracting the image, we use 28x28 input shape so the flattened vector has dimension 784. In total, there are 101 classes including \n",
    "* digits: 0 1 2 3 4 5 6 7 8 9\n",
    "* operators: ( ) [ ] + - =\n",
    "* lowercase_letters: a b c d e f g h i j k l m n o p q r s t u v w x y z\n",
    "* uppercase_letters: A B C E F G H I L M N P R S T V X Y\n",
    "* greek: \\Delta \\alpha \\beta \\gamma \\lambda \\mu \\phi \\pi \\sigma \\theta\n",
    "* miscellaneous: \\times = \\in \\pm ! \\rightarrow \\sin \\cos \\tan \\lim \\log \\exists \\forall \\sqrt / \\geq \\gt \\leq \\lt \\neq \\div\n",
    "* symbols: \\int \\infty \\sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25522476-e4bc-47b9-b542-14a65d24bc1e",
   "metadata": {},
   "source": [
    "# Section I: Deep Network Trained on Flattend Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3a2eb4-253d-4447-be37-912b773dd2af",
   "metadata": {},
   "source": [
    "First, since we've flattened the images, we build a purely dense network and train the model on the flattened images. The result turns out to be better than expectation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e9519a-8698-4b00-8f6c-6436beb5dcfb",
   "metadata": {},
   "source": [
    "Step 1: To fit in the model, we first tranfer numpy array into tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8012eb26-376b-4c4f-915b-cc0e9db0aff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_feature_values = train_ds['features'].values\n",
    "train_label_values = train_ds['label'].values\n",
    "test_feature_values = test_ds['features'].values\n",
    "test_label_values = test_ds['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a9e54ed-f90c-4195-97f1-79111f53da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_tensor = tf.convert_to_tensor(train_feature_values.tolist())\n",
    "train_label_tensor = tf.convert_to_tensor(train_label_values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "750926ab-b8e4-4328-a914-7a9535af51fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature_tensor = tf.convert_to_tensor(test_feature_values.tolist())\n",
    "test_label_tensor = tf.convert_to_tensor(test_label_values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ad1375-8525-49e6-8960-d2ad4fe64af1",
   "metadata": {},
   "source": [
    "Step 2: Build the dense network with three hidden dense layers including the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edd6a74c-8fd2-4feb-8163-2f06e6fb3f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               13029     \n",
      "=================================================================\n",
      "Total params: 246,885\n",
      "Trainable params: 246,885\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dense = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer((784)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    # The output layer has 101 nodes since we have 101 classes for this balanced data\n",
    "    # with 10 digits and 37 letters\n",
    "    tf.keras.layers.Dense(101, activation = 'softmax')\n",
    "])\n",
    "model_dense.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bab67111-fb7a-42f7-a77e-0ed8702bcc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dense.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ca30f9-e7a7-4fb9-bae5-7ddfcb54f59b",
   "metadata": {},
   "source": [
    "Step 3: Train the Dense Network and Evaluate the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed6b39b2-2aa1-4351-a8c4-0ca27563bd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "9716/9716 [==============================] - 19s 2ms/step - loss: 1.0680 - acc: 0.7004\n",
      "Epoch 2/5\n",
      "9716/9716 [==============================] - 18s 2ms/step - loss: 0.5629 - acc: 0.8219\n",
      "Epoch 3/5\n",
      "9716/9716 [==============================] - 18s 2ms/step - loss: 0.4731 - acc: 0.8468\n",
      "Epoch 4/5\n",
      "9716/9716 [==============================] - 18s 2ms/step - loss: 0.4236 - acc: 0.8615\n",
      "Epoch 5/5\n",
      "9716/9716 [==============================] - 18s 2ms/step - loss: 0.3903 - acc: 0.8719\n"
     ]
    }
   ],
   "source": [
    "history_dense = model_dense.fit(train_feature_tensor, train_label_tensor, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8d7d41c-8412-4e1f-842c-62a491cc2cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5499/5499 [==============================] - 5s 963us/step - loss: 1.1300 - acc: 0.7607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1300034523010254, 0.7606837749481201]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dense.evaluate(test_feature_tensor, test_label_tensor, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9214d978-8998-482e-a9a9-31aaf887d2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAuNklEQVR4nO3deXxUhb3+8c83CRAkCSA7hFVQhICJRkSpGvT2VxSL2qqE69Vad1vrXsUqO1Wv11ZL1VptrW21BmvVS5WrtgKCGxpkDSAioITNsIOsId/fH3MSQwghQCZnknner9e8nDnnzJknB2eeOcucY+6OiIjEr4SwA4iISLhUBCIicU5FICIS51QEIiJxTkUgIhLnVAQiInFORSASAjPLMbPCak472syej3YmiV8qAgmNma0ws51mts3MNpvZB2Z2o5nF1P+XZuZm9rWZJZUb1iAYFuoPcQ6nUEQOJqbecBKXvu/uqUBn4CHgHuCP4Uaq1CbgvHKPzwuGidR5KgKJCe6+xd0nAUOBH5lZBoCZNTKzR8zsKzNbZ2ZPmVnjYFyOmRWa2Z3Bt/M1Zvbj0nma2flmtjBY41hlZneVG3eBmc0ptybS9xAR/wpcWe7xlcBfyk9gZu3NbJKZbTSzpWZ2Xblxjc3sOTPbZGYLgVMree4/zKzIzJab2S2HtQArYWYnmtm04G8sMLMh5cZVumzMrKWZvR48Z6OZzYi1NTSpefoHlpji7h8DhcCZwaCHgOOBTKA70AEYWe4pbYGmwfBrgCfMrHkw7o/ADcEaRwYwBcDMsoBngRuAFsDvgUlm1qiKaK8BZ5lZs2D+ZwL/W2GavCB7e+AS4AEzOycYNwo4Lrh9D/hR6ZOCD9p/AnODv+Nc4DYz+14VeapkZg2Ceb4NtAZ+BrxgZicEk1S6bIA7g7+hFdAG+AWg89DUcyoCiUWrgWPNzIDrgdvdfaO7bwMeAHLLTbsXGOvue919MrAdOKHcuF5mlubum9z902D49cDv3X2mu+9z9z8Du4H+VWTaReSDdWhwmxQMA8DMOgIDgHvcfZe7zwH+wLdrEZcBvwz+jpXAhHLzPhVo5e5j3X2Puy8Dnqnwdx6u/kAK8FAwzynA68CwYPzBls1eoB3QOVimM1wnJKv3VAQSizoAG4l8Kz0GmBVsqtgMvBkML7XB3YvLPd5B5AMQ4IfA+cCXZvaumZ0eDO8M3Fk6z2C+HYl8k6/KX4h8sB+wWSh4bmlZlfoy+FtKx6+sMK5UZ6B9hTy/IPKN/Ei1B1a6e8lB8hxs2fwPsBR428yWmdnwo8ggdYSKQGKKmZ1K5MPqPWA9sBPo7e7NgltTd0+pciYBd//E3S8ksmnkNeClYNRKIt/Om5W7HePuLx5iljOIfFtuE+Qrr3QtJrXcsE7AquD+GiJlU35cqZXA8gp5Ut39/Or8nQexGuhYYft+WZ6DLRt33+bud7p7N2AIcIeZnXsUOaQOUBFITDCzNDO7gMh29ufdfX7wbfYZ4FEzax1M16E6287NrKGZXW5mTd19L7AVKP12/Axwo5mdZhFNzGxwhQ/xAwSbSL4PDKm4uSTY3PMB8KCZJQc7n68BSo//fwm418yam1k6kW32pT4GtpnZPcFO5UQzywhKsVqC1yy7BfPcAdwdHOqaE2TPq2rZBDvRuweb5bYA+8otN6mnVAQStn+a2TYi34rvA34N/Ljc+HuIbKr4yMy2Av/m230Ah3IFsCJ43o3A5QDung9cBzxO5BDQpcBV1Zmhuxe4e8FBRg8DuhD5Nv4qMMrd/x2MG0Nk08xyIjtw/1punvuAC4jsEF9OZE3oD0R2gldHByJrTuVvHYl88J8XzO9J4Ep3Xxw8p9JlA/Qgsoy3Ax8CT7r71GrmkDrKtB9IRCS+aY1ARCTOqQhEROJc1IrAzJ4Nfu254CDje5rZh2a2u/wvPkVEpHZFc43gOWBQFeM3ArcAj0Qxg4iIHELSoSc5Mu4+3cy6VDH+a+BrMxt8OPNt2bKld+ly0NmKiEglZs2atd7dW1U2LmpFUJPM7HoipwWgU6dO5Ofnh5xIRKRuMbMvDzauTuwsdven3T3b3bNbtaq00ERE5AjViSIQEZHoURGIiMS5qO0jMLMXgRygpUUupTcKaADg7k+ZWVsgH0gDSszsNqCXu2+NViYRia69e/dSWFjIrl27Dj2xREVycjLp6ek0aNCg2s+J5lFDww4xfi2QHq3XF5HaV1hYSGpqKl26dCFy3jqpTe7Ohg0bKCwspGvXrtV+njYNiUiN2bVrFy1atFAJhMTMaNGixWGvkakIRKRGqQTCdSTLP26K4IuNX3Dbm7exd9/esKOIiMSUuCmCResX8ZuZv+G5Oc+FHUVEomTDhg1kZmaSmZlJ27Zt6dChQ9njPXv2VPnc/Px8brnllkO+xhlnnFEjWadNm8YFF1xQI/M6WnXil8U1YXCPwZzW4TTGTh/LFSddQXJSctiRRKSGtWjRgjlz5gAwevRoUlJSuOuub89pWVxcTFJS5R972dnZZGdnH/I1PvjggxrJGkviZo3AzBh/zngKtxbyzKxnwo4jIrXkqquu4sYbb+S0007j7rvv5uOPP+b0008nKyuLM844g88++wzY/xv66NGjufrqq8nJyaFbt25MmDChbH4pKSll0+fk5HDJJZfQs2dPLr/8ckov9DV58mR69uzJKaecwi233HLIb/4bN27koosuom/fvvTv35958+YB8O6775at0WRlZbFt2zbWrFnDWWedRWZmJhkZGcyYMeOol1HcrBEAnNv1XHK65PDLGb/k6qyradKwSdiRROqt2968jTlr59ToPDPbZvLYoMcO+3mFhYV88MEHJCYmsnXrVmbMmEFSUhL//ve/+cUvfsE//vGPA56zePFipk6dyrZt2zjhhBO46aabDjg2f/bs2RQUFNC+fXsGDBjA+++/T3Z2NjfccAPTp0+na9euDBtW5ZH0AIwaNYqsrCxee+01pkyZwpVXXsmcOXN45JFHeOKJJxgwYADbt28nOTmZp59+mu9973vcd9997Nu3jx07dhz28qgobtYIILJWMG7gONZ9s44nPnki7DgiUksuvfRSEhMTAdiyZQuXXnopGRkZ3H777RQUVH4J6sGDB9OoUSNatmxJ69atWbdu3QHT9OvXj/T0dBISEsjMzGTFihUsXryYbt26lR3HX50ieO+997jiiisAOOecc9iwYQNbt25lwIAB3HHHHUyYMIHNmzeTlJTEqaeeyp/+9CdGjx7N/PnzSU1NPdLFUiau1ggAvtPpOwzqPoj/fv+/uTH7RtIapYUdSaReOpJv7tHSpMm3a/8jRoxg4MCBvPrqq6xYsYKcnJxKn9OoUaOy+4mJiRQXFx/RNEdj+PDhDB48mMmTJzNgwADeeustzjrrLKZPn84bb7zBVVddxR133MGVV155VK8TV2sEpcYNHMfGnRt57KPHwo4iIrVsy5YtdOjQAYDnnnuuxud/wgknsGzZMlasWAHAxIkTD/mcM888kxdeeAGI7Hto2bIlaWlpfPHFF/Tp04d77rmHU089lcWLF/Pll1/Spk0brrvuOq699lo+/fTTo84cl0WQ3T6bi3pexK8+/BUbd24MO46I1KK7776be++9l6ysrBr/Bg/QuHFjnnzySQYNGsQpp5xCamoqTZs2rfI5o0ePZtasWfTt25fhw4fz5z//GYDHHnuMjIwM+vbtS4MGDTjvvPOYNm0aJ510EllZWUycOJFbb731qDNb6V7uuiI7O9tr4sI089fN56SnTuKeAffw4H88WAPJRGTRokWceOKJYccI3fbt20lJScHd+elPf0qPHj24/fbba+31K/t3MLNZ7l7p8bFxuUYA0KdNH3Izcpnw8QTWbT9wJ5CIyJF65plnyMzMpHfv3mzZsoUbbrgh7EhVitsiABidM5pdxbt46L2Hwo4iIvXI7bffzpw5c1i4cCEvvPACxxxzTNiRqhTXRXB8i+P50Uk/4nf5v6Nwa2HYcUTqhbq2ubm+OZLlH9dFADDy7JGUeAnjp48PO4pInZecnMyGDRtUBiEpvR5BcvLhnUIn7n5HUFGXZl247uTrePrTp7l7wN10a94t7EgidVZ6ejqFhYUUFRWFHSVulV6h7HDE7VFD5a3etprjJhzH0N5Dee6i52p03iIisUBHDR1C+9T2/CT7J/x13l9ZvH5x2HFERGqViiBwz3fuoXFSY0ZNGxV2FBGRWhW1IjCzZ83sazNbcJDxZmYTzGypmc0zs5OjlaU6WjdpzW39b+OlgpeYu3ZumFFERGpVNNcIngMGVTH+PKBHcLse+F0Us1TLnaffSdNGTRk5bWTYUUREak3UisDdpwNVncjnQuAvHvER0MzM2kUrT3U0b9ycu864i0mfTeLjVR+HGUVEpNaEuY+gA7Cy3OPCYNgBzOx6M8s3s/xoH5Z262m30vKYloyYOiKqryMiEivqxM5id3/a3bPdPbtVq1ZRfa3URqkMHzCct794m+lfTo/qa4mIxIIwi2AV0LHc4/RgWOhuOvUm2qW04/4p9+sXkiJS74VZBJOAK4Ojh/oDW9x9TYh5yhzT4BjuO/M+Znw1g38t+1fYcUREoiqah4++CHwInGBmhWZ2jZndaGY3BpNMBpYBS4FngJ9EK8uRuPbka+nUtJPWCkSk3ovauYbcvcorNnvk0/Wn0Xr9o9UoqREjzxrJtf+8lkmfTeLCnheGHUlEJCrqxM7isPwo80d0P7Y7I6aOoMRLwo4jIhIVKoIqJCUkMSZnDPO/ns/fC/4edhwRkahQERzC0N5D6d2qN6OmjaK4pOYvdC0iEjYVwSEkJiQyduBYPtvwGS/MeyHsOCIiNU5FUA0X97yYk9udzOh3R7Nn356w44iI1CgVQTWYGeMHjmfF5hU8O/vZsOOIiNQoFUE1Deo+iDM6nsG46ePYuXdn2HFERGqMiqCaStcKVm9bze9n/T7sOCIiNUZFcBgGdh3IuV3P5YEZD7B9z/aw44iI1AgVwWEaN3AcRTuK+O3M34YdRUSkRqgIDtPpHU9ncI/BPPzBw2zetTnsOCIiR01FcATGDhzL5l2befTDR8OOIiJy1FQER+DkdifzwxN/yKMfPcr6HevDjiMiclRUBEdo7MCxbN+znYfffzjsKCIiR0VFcIR6terF5X0v5/GPH2fNtpi4no6IyBFRERyFUWePYs++PTz43oNhRxEROWIqgqPQ/dju/Djzx/x+1u/5astXYccRETkiKoKjNOLsEQCMe3dcyElERI6MiuAodWraiRtOuYE/zfkTSzcuDTuOiMhhUxHUgHu/cy8NExsy5t0xYUcRETlsUS0CMxtkZp+Z2VIzG17J+M5m9o6ZzTOzaWaWHs080dIutR0397uZF+a9wMKihWHHERE5LFErAjNLBJ4AzgN6AcPMrFeFyR4B/uLufYGxQJ09/ObuAXeT0jCFUdNGhR1FROSwRHONoB+w1N2XufseIA+4sMI0vYApwf2plYyvM1oe05Lb+9/OywtfZvaa2WHHERGptmgWQQdgZbnHhcGw8uYCPwjuXwykmlmLijMys+vNLN/M8ouKiqIStibcfvrtNE9uzoipI8KOIiJSbWHvLL4LONvMZgNnA6uAfRUncven3T3b3bNbtWpV2xmrrVlyM35+xs954/M3+HDlh2HHERGplmgWwSqgY7nH6cGwMu6+2t1/4O5ZwH3BsM1RzBR1PzvtZ7Ru0lprBSJSZ0SzCD4BephZVzNrCOQCk8pPYGYtzaw0w71Anb8yfErDFO79zr28s/wdpi6fGnYcEZFDiloRuHsxcDPwFrAIeMndC8xsrJkNCSbLAT4zsyVAG+CX0cpTm27MvpEOqR24f+r9uHvYcUREqmR17YMqOzvb8/Pzw45xSE/lP8VNb9zE5P+czHk9zgs7jojEOTOb5e7ZlY0Le2dxvXV11tV0adZFawUiEvNUBFHSMLEho88ezadrPuXVxa+GHUdE5KBUBFF0ed/LOaHFCYycOpJ9JQccFSsiEhNUBFGUlJDEmJwxFBQVMLFgYthxREQqpSKIskt7X0qf1n0YNW0UxSXFYccRETmAiiDKEiyBcQPHsXTjUv4y9y9hxxEROYCKoBYMOWEIp7Y/lTHvjmF38e6w44iI7EdFUAvMjPHnjOerLV/xh0//EHYcEZH9qAhqyXe7fZczO53J+Bnj2bF3R9hxRETKqAhqSelawdrta/ndJ78LO46ISBkVQS06q/NZ/L/j/h8Pvf8Q23ZvCzuOiAigIqh14waOY/2O9fxm5m/CjiIiAqgIal2/Dv0YcsIQHvngETbt3BR2HBERFUEYxuaMZcvuLfzqw1+FHUVEREUQhpPansRlvS/jsY8eo+ib2L0Gs4jEBxVBSMbkjGFn8U4eeu+hsKOISJxTEYSkZ8ueXNH3Cp7Mf5JVW1cd+gkiIlGiIgjRyLNHUlxSzAMzHgg7iojEMRVBiLo178Y1WdfwzKfPsGLzirDjiEicUhGE7P6z7ifBEhj77tiwo4hInIpqEZjZIDP7zMyWmtnwSsZ3MrOpZjbbzOaZ2fnRzBOL0tPSuSn7Jv48988s2bAk7DgiEoeiVgRmlgg8AZwH9AKGmVmvCpPdD7zk7llALvBktPLEsuHfGU5yUjKjp40OO4qIxKForhH0A5a6+zJ33wPkARdWmMaBtOB+U2B1FPPErDYpbbil3y3kLchj/rr5YccRkTgTzSLoAKws97gwGFbeaOC/zKwQmAz8rLIZmdn1ZpZvZvlFRfXzB1g/H/BzUhulMmraqLCjiEicCXtn8TDgOXdPB84H/mpmB2Ry96fdPdvds1u1alXrIWvDsY2P5c7T7+TVxa+Svzo/7DgiEkeiWQSrgI7lHqcHw8q7BngJwN0/BJKBllHMFNNu638bxzY+lhFTR4QdRUTiSDSL4BOgh5l1NbOGRHYGT6owzVfAuQBmdiKRIqif236qIa1RGvcMuIc3l77Je1+9F3YcEYkTUSsCdy8GbgbeAhYROTqowMzGmtmQYLI7gevMbC7wInCVu3u0MtUFPz31p7Rp0ob7p9xPnC8KEaklSdGcubtPJrITuPywkeXuLwQGRDNDXdOkYRPuO/M+bnnzFt5Z/g7/0e0/wo4kIvVc2DuLpRLXn3I9HdM6aq1ARGqFiiAGNUpqxIizRjBz1Uze+PyNsOOISD2nIohRV2VexXHNj2PE1BGUeEnYcUSkHlMRxKgGiQ0YnTOaOWvn8MqiV8KOIyL1mIoghg3LGMaJLU9k5NSR7CvZF3YcEamnVAQxLDEhkbEDx7Jo/SL+Nv9vYccRkXpKRRDjfnDiD8hsm8nod0ezd9/esOOISD1UrSIwsyal5wAys+PNbIiZNYhuNAFIsATGDRzHsk3LeG7Oc2HHEZF6qLprBNOBZDPrALwNXAE8F61Qsr/BPQbTP70/Y6ePZVfxrrDjiEg9U90iMHffAfwAeNLdLwV6Ry+WlGdmjB84nsKthTw96+mw44hIPVPtIjCz04HLgdJfOCVGJ5JU5pyu55DTJYcHZjzAN3u+CTuOiNQj1S2C24B7gVeDE8d1A6ZGLZUcoHStYN0363jikyfCjiMi9Ygd7rlsgp3GKe6+NTqRqpadne35+fF74ZbzXzifmatmsvzW5aQ1Sjv0E0READOb5e7ZlY2r7lFDfzOzNDNrAiwAFprZz2sypFTPuIHj2LhzI49++GjYUUSknqjupqFewRrARcD/AV2JHDkkteyU9qdwcc+L+fVHv2bDjg1hxxGReqC6RdAg+N3ARcAkd98L6PzIIRmTM4Ztu7fxyAePhB1FROqB6hbB74EVQBNgupl1BkLZRyDQp00fcjNymfDxBNZtXxd2HBGp46pVBO4+wd07uPv5HvElMDDK2aQKo3NGs7t4Nw++92DYUUSkjqvuzuKmZvZrM8sPbr8isnYgITm+xfH86KQf8bv837Fyy8qw44hIHVbdTUPPAtuAy4LbVuBP0Qol1TPi7BG4O7+c8cuwo4hIHVbdIjjO3Ue5+7LgNgbodqgnmdkgM/vMzJaa2fBKxj9qZnOC2xIz23yY+eNal2ZduO7k6/jj7D+ybNOysOOISB1V3SLYaWbfKX1gZgOAnVU9wcwSgSeA84BewDAz61V+Gne/3d0z3T0T+C2gS3EdpvvOuo+khCTGvDsm7CgiUkdVtwhuBJ4wsxVmtgJ4HLjhEM/pBywN1iD2AHnAhVVMPwx4sZp5JNA+tT0/PfWnPD/veRYVLQo7jojUQdU9amiuu58E9AX6unsWcM4hntYBKL8XszAYdoDgcNSuwJTq5JH93TPgHhonNWb0u6PDjiIiddBhXaHM3beWO8fQHTWYIxd42d0rvTCvmV1fesRSUVFRDb5s/dCqSStu638bLxW8xNy1c8OOIyJ1zNFcqtIOMX4V0LHc4/RgWGVyqWKzkLs/7e7Z7p7dqlWrw0sZJ+464y6aJTdj5LSRYUcRkTrmaIrgUKeY+AToYWZdzawhkQ/7SRUnMrOeQHPgw6PIEveaJTfjrtPvYtJnk5hZODPsOCJSh1RZBGa2zcy2VnLbBrSv6rnuXgzcDLwFLAJeCq5lMNbMhpSbNBfI88M9H7Yc4JbTbqHlMS0ZMXVE2FFEpA5Jqmqku6cezczdfTIwucKwkRUejz6a15BvpTZKZfiA4dz1r7t4d8W7nN3l7LAjiUgdcDSbhiQG/eTUn9AupR0jpkZ+dSwicigqgnqmcYPG3H/W/cz4agZvf/F22HFEpA5QEdRD12RdQ+emnbl/6v1aKxCRQ1IR1EONkhox8uyR5K/OZ9JnBxyoJSKyHxVBPXXlSVfS49gejJg6ghIvCTuOiMQwFUE9lZSQxJicMcz/ej5/L/h72HFEJIapCOqxoRlDyWidwchpIykuKQ47jojEKBVBPZZgCYzNGcuSDUt4ft7zYccRkRilIqjnLup5ESe3O5kx745hz749YccRkRikIqjnzIzxA8ezYvMKnp39bNhxRCQGqQjiwKDugxjQcQDjpo9j594qLywnInFIRRAHzIzx54xn9bbVPJX/VNhxRCTGqAjiRE6XHM7tei4Pvvcg2/dsDzuOiMQQFUEcGX/OeIp2FPHbmb8NO4qIxBAVQRzpn96fC46/gIc/eJjNuzaHHUdEYoSKIM6MzRnL5l2b+fWHvw47iojECBVBnMlql8UlvS7h0Y8eZf2O9WHHEZEYoCKIQ2NyxvDNnm94+P2Hw44iIjFARRCHerXqxX/1/S8e//hx1mxbE3YcEQmZiiBOjTp7FHv27eGBGQ+EHUVEQqYiiFPHHXscV2ddze9n/Z4vN38ZdhwRCVFUi8DMBpnZZ2a21MyGH2Say8xsoZkVmNnfoplH9nf/WfdHfnU8fXzYUUQkRFErAjNLBJ4AzgN6AcPMrFeFaXoA9wID3L03cFu08siBOjXtxA2n3MCf5vyJpRuXhh1HREISzTWCfsBSd1/m7nuAPODCCtNcBzzh7psA3P3rKOaRSvzizF/QMLEhY94dE3YUEQlJNIugA7Cy3OPCYFh5xwPHm9n7ZvaRmQ2qbEZmdr2Z5ZtZflFRUZTixqe2KW35Wb+f8cK8Fyj4uiDsOCISgrB3FicBPYAcYBjwjJk1qziRuz/t7tnunt2qVavaTRgH7h5wNykNUxg1bVTYUUQkBNEsglVAx3KP04Nh5RUCk9x9r7svB5YQKQapRS2OacHt/W/nH4v+wadrPg07jojUsmgWwSdADzPramYNgVxgUoVpXiOyNoCZtSSyqWhZFDPJQdxx+h00T27OyKkjw44iIrUsakXg7sXAzcBbwCLgJXcvMLOxZjYkmOwtYIOZLQSmAj939w3RyiQH1zS5KXcPuJs3Pn+DD1d+GHYcEalF5u5hZzgs2dnZnp+fH3aMeumbPd/QbUI3Mlpn8M6V74QdR0RqkJnNcvfsysaFvbNYYkiThk249zv3MmX5FKYsnxJ2HBGpJSoC2c+N2TfSIbUDI6aOoK6tLYrIkVERyH6Sk5IZcdYIPlj5AW8ufTPsOCJSC1QEcoAfZ/2Yrs26cv/U+ynxkrDjiEiUqQjkAA0TGzI6ZzSfrvmUzo915q6372LW6lnaVCRSTyWFHUBi0xV9ryA5KZnn5z3PhJkT+NWHv6L7sd3J7Z1LbkYuvVv3DjuiiNQQHT4qh7Rx50ZeXfQqeQV5TFk+hRIvIaN1Brm9cxmaMZTux3YPO6KIHEJVh4+qCOSwrNu+jpcXvkxeQR7vffUeANntsxmWMYzLel9Gelp6yAlFpDIqAomKr7Z8xUsFL5G3II9Za2YBcGanM8nNyOWSXpfQuknrkBOKSCkVgUTd5xs+Z2LBRF5c8CILixaSaImc2+1ccnvncvGJF9MsuVnYEUXimopAatWCrxfw4vwXySvIY9mmZTRMbMig7oPI7Z3L90/4PikNU8KOKBJ3VAQSCncnf3U+eQvymFgwkVXbVnFMg2P4/vHfJzcjl0HdB5GclBx2TJG4oCKQ0JV4Ce9/9T55C/L4+8K/U7SjiLRGaVzc82JyM3I5t+u5NEhsEHZMkXpLRSAxpbikmCnLp5C3II9XFr3Clt1baNG4BZf0uoTcjFzO7HQmiQmJYccUqVdUBBKzdhfv5q0v3iJvQR7/+9n/smPvDtqntueyXpeRm5FLvw79MLOwY4rUeSoCqRO+2fMNry95nbyCPCZ/Ppk9+/bQpVkXcnvnMqzPMPq07qNSEDlCKgKpc7bs2sJri18jryCPf33xL/b5Pk5seSK5GZFTXBzf4viwI4rUKSoCqdOKvinilUWv8OKCF5n+5XQcJ6ttFrkZuQztPZTOzTqHHVEk5qkIpN5YtXUVf1/4d/IW5DFz1UwAzuh4Brm9c7m096W0TWkbckKR2KQikHpp2aZlZae4mLtuLgmWQE6XHHJ75/KDE39Ai2NahB1RJGaEVgRmNgj4DZAI/MHdH6ow/irgf4BVwaDH3f0PVc1TRSCVWVi0kIkLIqe4+Hzj5yQlJPG9475HbkYuQ04YQlqjtLAjioQqlCIws0RgCfBdoBD4BBjm7gvLTXMVkO3uN1d3vioCqYq7M2ftHPIW5JFXkMdXW74iOSmZwT0Gk5uRy+Aeg2ncoHHYMUVqXVVFEM0L0/QDlrr7siBEHnAhsLDKZ4kcBTMjq10WWe2yePA/HmRm4UxeXPAiLxW8xD8W/YOUhilceMKFDMsYxneP+y4NExuGHVkkdNG8VGUHYGW5x4XBsIp+aGbzzOxlM+tY2YzM7Hozyzez/KKiomhklXoowRI4vePpTDhvAqvuWMU7V77DsIxhTP58Mhe8eAFtH2nLdZOu451l77CvZF/YcUVCE81NQ5cAg9z92uDxFcBp5TcDmVkLYLu77zazG4Ch7n5OVfPVpiE5Wnv27eHfy/7Niwte5LXFr7F9z3baNGnDpb0uZVifYfRP70+C6XLeUr+EtY/gdGC0u38veHwvgLs/eJDpE4GN7t60qvmqCKQm7dy7k8mfTyavII/Xl7zOruJddGraiaG9h5KbkUtW2yz9mlnqhbCKIInIzuJziRwV9Anwn+5eUG6adu6+Jrh/MXCPu/evar4qAomWbbu3MemzSeQV5PHm0jcpLimmx7E9yn7N3KtVr7AjihyxMA8fPR94jMjho8+6+y/NbCyQ7+6TzOxBYAhQDGwEbnL3xVXNU0UgtWHjzo28sugV8hbkMXXFVEq8hL5t+pLbO5ehGUPp1rxb2BFFDot+UCZyFNZuX8vLC18mb0Ee7698H4B+HfqR2zuXy3pfRoe0yo6BEIktKgKRGvLVlq+YuGAieQV5fLrmUwzjzM5nMixjGD888Ye0atIq7IgilVIRiETBkg1Lyn7NvGj9IhIsgRNbnkhm20yy2maR2TaTzLaZOtWFxAQVgUgUuTsLvl7AK4teYdaaWcxeO5vCrYVl4zumdSSrXRaZbTIj/22bSeemnXU0ktSqsH5ZLBIXzIw+bfrQp02fsmHrd6xnzto5zFk7h9lrZzNn7RxeX/I6JV4CQLPkZvutOWS1zaJny566brOEQmsEIrVkx94dLPh6AbPXzC4riHnr5rGzeCcAjRIbkdE6o2yTUlbbLPq26Utqo9SQk0t9oE1DIjFqX8k+lmxYst+aw+y1s1m/Yz0AhtH92O77rz20y9J1F+SwqQhE6hB3Z/W21fsVw5y1c1i2aVnZNG2atDlgv0P3Y7vr1BhyUNpHIFKHmBkd0jrQIa0DFxx/Qdnwzbs2M2/dvMimpXVzmL1mNv9e9m+KS4oBaNKgCSe1PWm//Q69W/cmOSk5rD9F6gitEYjUYbuLd7OwaOF+aw9z185l255tACQlJFV6SGvzxs1DTi61TZuGROJIiZewbNOyA45aWr1tddk0nZt2PmDTUse0jjqktR5TEYgI67avY+66ufttWlqyYQlO5DPg2MbHHnBI6wktTyApQVuQ6wMVgYhU6ps93zBv3byyNYfZa2czf918du/bDUByUjJ9WvfZryD6tulLk4ZNQk4uh0tFICLVVlxSzOL1iyPlUG7tYdOuTUDkkNbjWxxfVg6lm5ZaN2kdcnKpiopARI6Ku7Ny68r9fgw3Z+0cvtzyZdk07VPbR3ZGl9vv0K15Nx3SGiNUBCISFRt3bmTu2rn7HbW0qGgR+zxyDejUhqkHHNLaq1UvGiU1Cjl5/FERiEit2VW8iwVfL9hv09LctXP5Zu83ADRIaECvVr3IbJvJ8S2Op2uzrnRp1oWuzbvSpkkbHbkUJSoCEQnVvpJ9fLHpi/02Lc1dN5e129fuN13jpMZlpdClaeS/XZt1jTxu1oXmyc1VFEdIRSAiMembPd+wYvMKlm9eHvnvpuUs3xzcNi1ny+4t+02f1ijt22KopChSGqaE9JfEPp1iQkRiUpOGTejduje9W/eudPzmXZu/LYdNy8tKY8mGJbz9xdvs2Ltjv+lbHtOyrBjKNjkFjzs37ax9EwehNQIRqZPcnaIdRZUWxfLNy/ly85fsLdm733Pap7Y/aFGkp6XX6x/PhbZpyMwGAb8BEoE/uPtDB5nuh8DLwKnuXuWnvIpARKpjX8k+1mxfs39RbPl281Ph1sKyCwUBJFoinZp22q8cyu/IbpvStk4fChvKpiEzSwSeAL4LFAKfmNkkd19YYbpU4FZgZrSyiEj8SUxIJD0tnfS0dM7sfOYB4/fu28vKrSsrLYrJSycfsCO7UWIjujTrckBRlO6faNG4RZ3dkR3N9aB+wFJ3XwZgZnnAhcDCCtONA/4b+HkUs4iI7KdBYgO6Ne9Gt+bdKh2/c+9OvtzyZVlRlG122rScT1Z/wsadG/ebPqVhSpU7stMapdXGn3VEolkEHYCV5R4XAqeVn8DMTgY6uvsbZnbQIjCz64HrATp16hSFqCIi+2vcoDE9W/akZ8uelY7funvrfkc6lS+KKcunsH3P9v2mP7bxsVXuyG7coHFt/FmVCm3PiJklAL8GrjrUtO7+NPA0RPYRRDeZiMihpTVKo2+bvvRt0/eAce7Oxp0by4qhfFHMXzeff372z7IT+5Vqm9L2oEXRMa0jDRIbRO1viWYRrAI6lnucHgwrlQpkANOC7WptgUlmNuRQO4xFRGKZmdHimBa0OKYF2e0P3D9b4iWs276u0qL4cOWHTFwwsew0HQAJlkB6Wjq3nnYrd5x+R43njWYRfAL0MLOuRAogF/jP0pHuvgVoWfrYzKYBd6kERKS+S7AE2qW2o11qO87oeMYB44tLilm1ddUBRdEupV1U8kStCNy92MxuBt4icvjos+5eYGZjgXx3nxSt1xYRqcuSEpLo3KwznZt1JqdLTvRfL5ozd/fJwOQKw0YeZNqcaGYREZHK1d1fR4iISI1QEYiIxDkVgYhInFMRiIjEORWBiEicUxGIiMQ5FYGISJyrcxemMbMi4MsjfHpLYH0NxqkpsZoLYjebch0e5To89TFXZ3dvVdmIOlcER8PM8g92YYYwxWouiN1synV4lOvwxFsubRoSEYlzKgIRkTgXb0XwdNgBDiJWc0HsZlOuw6NchyeucsXVPgIRETlQvK0RiIhIBSoCEZE4Vy+LwMwGmdlnZrbUzIZXMr6RmU0Mxs80sy4xkusqMysysznB7dpayvWsmX1tZgsOMt7MbEKQe56ZnRwjuXLMbEu55VXptS5qOFNHM5tqZgvNrMDMbq1kmlpfXtXMVevLK3jdZDP72MzmBtnGVDJNrb8nq5krrPdkopnNNrPXKxlX88vK3evVjcjV0L4AugENgblArwrT/AR4KrifC0yMkVxXAY+HsMzOAk4GFhxk/PnA/wEG9AdmxkiuHOD1Wl5W7YCTg/upwJJK/h1rfXlVM1etL6/gdQ1ICe43AGYC/StME8Z7sjq5wnpP3gH8rbJ/r2gsq/q4RtAPWOruy9x9D5AHXFhhmguBPwf3XwbONTOLgVyhcPfpwMYqJrkQ+ItHfAQ0M7PoXDz18HLVOndf4+6fBve3AYuADhUmq/XlVc1coQiWw/bgYYPgVvEolVp/T1YzV60zs3RgMPCHg0xS48uqPhZBB2BluceFHPiGKJvG3YuBLUCLGMgF8MNgc8LLZtYxypmqq7rZw3B6sGr/f2bWuzZfOFglzyLyTbK8UJdXFbkgpOUVbOqYA3wN/MvdD7rMavE9WZ1cUPvvyceAu4GSg4yv8WVVH4ugLvsn0MXd+wL/4tvWl8p9SuT8KScBvwVeq60XNrMU4B/Abe6+tbZe91AOkSu05eXu+9w9E0gH+plZRm29dlWqkatW35NmdgHwtbvPiubrVFQfi2AVUL6104NhlU5jZklAU2BD2LncfYO77w4e/gE4JcqZqqs6y7TWufvW0lV7d58MNDCzltF+XTNrQOTD9gV3f6WSSUJZXofKFdbyqpBhMzAVGFRhVBjvyUPmCuE9OQAYYmYriGw+PsfMnq8wTY0vq/pYBJ8APcysq5k1JLIzZVKFaSYBPwruXwJM8WDPS5i5KmxHHkJkO28smARcGRwN0x/Y4u5rwg5lZm1Lt42aWT8i/z9H9cMjeL0/Aovc/dcHmazWl1d1coWxvILXamVmzYL7jYHvAosrTFbr78nq5Krt96S73+vu6e7ehchnxBR3/68Kk9X4sko6mifHIncvNrObgbeIHKnzrLsXmNlYIN/dJxF5w/zVzJYS2RmZGyO5bjGzIUBxkOuqaOcCMLMXiRxR0tLMCoFRRHac4e5PAZOJHAmzFNgB/DhGcl0C3GRmxcBOILcWCn0AcAUwP9i2DPALoFO5XGEsr+rkCmN5QeSIpj+bWSKR8nnJ3V8P+z1ZzVyhvCcrivay0ikmRETiXH3cNCQiIodBRSAiEudUBCIicU5FICIS51QEIiJxTkUgEjCzfeXOMjnHKjlD7FHMu4sd5CyqImGrd78jEDkKO4PTDYjEFa0RiByCma0ws4fNbL5Fzl/fPRjexcymBCcke8fMOgXD25jZq8HJ3eaa2RnBrBLN7BmLnPv+7eDXrJjZLRa5jsA8M8sL6c+UOKYiEPlW4wqbhoaWG7fF3fsAjxM5OyRETtz25+CEZC8AE4LhE4B3g5O7nQwUBMN7AE+4e29gM/DDYPhwICuYz43R+dNEDk6/LBYJmNl2d0+pZPgK4Bx3Xxac2G2tu7cws/VAO3ffGwxf4+4tzawISC93srLSU0P/y917BI/vARq4+3gzexPYTuRsoK+VO0e+SK3QGoFI9fhB7h+O3eXu7+PbfXSDgSeIrD18EpxRUqTWqAhEqmdouf9+GNz/gG9P+HU5MCO4/w5wE5Rd+KTpwWZqZglAR3efCtxD5JTCB6yViESTvnmIfKtxuTN3Arzp7qWHkDY3s3lEvtUPC4b9DPiTmf0cKOLbs4zeCjxtZtcQ+eZ/E3Cw01AnAs8HZWHAhODc+CK1RvsIRA4h2EeQ7e7rw84iEg3aNCQiEue0RiAiEue0RiAiEudUBCIicU5FICIS51QEIiJxTkUgIhLn/j++GqpbN/lXnQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_train = history_dense.history['loss']\n",
    "plt.plot(loss_train, 'g', label='Training loss')\n",
    "plt.title('Dense Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig(\"train_loss_dense.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb8ebda-905b-4793-8a61-d1cda2d666a4",
   "metadata": {},
   "source": [
    "Comments: \n",
    "\n",
    "* After 5 epochs, the pure dense model has test accuracy higher than 76% percent. \n",
    "* Although the model still has minor over-fitting, the accuracy is higher than we expected. Thus, we believe that using a dense network trained on flattened image is a good option for recognizing the mathematical expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6475907f-1f55-4e29-926b-54b7c023d7ea",
   "metadata": {},
   "source": [
    "# Section II: Pre-Trained ResNet Model trained on Unflattened Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f668427-6ead-4702-8ecc-b5c340fd55ba",
   "metadata": {},
   "source": [
    "In this section, we use the ResNet50 model, a convolutional neural network that is 50 layers deep for image classification, to predict the corresponding latex codes using unflattened images. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fda3ee4-eb1a-49ee-98a3-08e99d3077ff",
   "metadata": {},
   "source": [
    "Step 1: Reshape the array to unflatten and expand the image datapoints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d4afabf-0aad-4c3b-998a-61faaf13cc87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_image_ds = train_ds\n",
    "test_image_ds = test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd7604b3-ae3b-4c69-b2eb-863fb833d3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_image_ds)):\n",
    "    arr = train_image_ds['features'][i]\n",
    "    train_image_ds['features'][i] = arr.reshape((28,28,1))\n",
    "for i in range(len(test_image_ds)):\n",
    "    arr = test_image_ds['features'][i]\n",
    "    test_image_ds['features'][i] = arr.reshape((28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb61f511-4bb0-4cf8-b477-22835c453c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_values = train_image_ds['features'].values\n",
    "test_image_values = test_image_ds['features'].values\n",
    "train_image_tensor = tf.convert_to_tensor(train_image_values.tolist())\n",
    "test_image_tensor = tf.convert_to_tensor(test_image_values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14af5b73-dfdc-4eb4-87be-60a02a630e39",
   "metadata": {},
   "source": [
    "Step 2: Build our ResNet model with modified input layer and an additional output layer whose dimension corresponds to the number of classes in our dataset using the original ResNet50 model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79c17949-2238-455a-93d0-a19ae21cf490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications.resnet50 import decode_predictions\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0ad5df9-4a23-41a8-836c-a7877dc893c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c647c1db-deab-4395-a56a-9b6624725a99",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3e8c93-cc8e-41e5-8c12-ac6a116f4675",
   "metadata": {},
   "source": [
    "Notice that the input layer of ResNet50 has shape (224, 224, 3), which doesn' match our input shape. Thus, we modified the first layer with input shape (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "effd0039-5150-4ab0-bd89-6bd249f2685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5cc3724-c277-41fd-9746-911b3eb583c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_name': 'InputLayer',\n",
       " 'config': {'batch_input_shape': (None, 224, 224, 3),\n",
       "  'dtype': 'float32',\n",
       "  'sparse': False,\n",
       "  'ragged': False,\n",
       "  'name': 'input_1'},\n",
       " 'name': 'input_1',\n",
       " 'inbound_nodes': []}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config['layers'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f576f651-0e19-4986-9798-e6f2cb68b5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_name': 'ZeroPadding2D',\n",
       " 'config': {'name': 'conv1_pad',\n",
       "  'trainable': True,\n",
       "  'dtype': 'float32',\n",
       "  'padding': ((3, 3), (3, 3)),\n",
       "  'data_format': 'channels_last'},\n",
       " 'name': 'conv1_pad',\n",
       " 'inbound_nodes': [[['input_1', 0, 0, {}]]]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config['layers'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "044e90af-3f08-44a3-8fa1-3a1f03ad3948",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config['layers'][0] = {\n",
    "                      'name': 'our_input',\n",
    "                      'class_name': 'InputLayer',\n",
    "                      'config': {\n",
    "                          'batch_input_shape': (None, 28, 28, 1),\n",
    "                          'dtype': 'float32',\n",
    "                          'sparse': False,\n",
    "                          'ragged': False,\n",
    "                          'name': 'our_input'\n",
    "                      },\n",
    "                      'name': 'our_input',\n",
    "                      'inbound_nodes': []\n",
    "                  }\n",
    "model_config['layers'][1]['inbound_nodes'] = [[['our_input', 0, 0, {}]]]\n",
    "model_config['input_layers'] = [['our_input', 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ef58ee1-db41-4520-8b37-d38d1b81f2e4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "our_input (InputLayer)          [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 34, 34, 1)    0           our_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 14, 14, 64)   3200        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 14, 14, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 14, 14, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 16, 16, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 7, 7, 64)     0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 7, 7, 64)     4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 7, 7, 64)     256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 7, 7, 64)     0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 7, 7, 64)     36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 7, 7, 64)     256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 7, 7, 64)     0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 7, 7, 256)    16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 7, 7, 256)    16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 7, 7, 256)    1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 7, 7, 256)    1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 7, 7, 256)    0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 7, 7, 256)    0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 7, 7, 64)     16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 7, 7, 64)     256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 7, 7, 64)     0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 7, 7, 64)     36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 7, 7, 64)     256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 7, 7, 64)     0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 7, 7, 256)    16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 7, 7, 256)    1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 7, 7, 256)    0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 7, 7, 256)    0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 7, 7, 64)     16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 7, 7, 64)     256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 7, 7, 64)     0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 7, 7, 64)     36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 7, 7, 64)     256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 7, 7, 64)     0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 7, 7, 256)    16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 7, 7, 256)    1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 7, 7, 256)    0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 7, 7, 256)    0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,630,440\n",
      "Trainable params: 25,577,320\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = model.__class__.from_config(model_config, custom_objects={})\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27caba3-3f75-4980-a93b-88c909e7067b",
   "metadata": {},
   "source": [
    "Notice that to actually use the pre-trained model, we need to freeze most hidden layers in the ResNet50. \n",
    "After around 30 trials setting only the last 1, 3, 6, 9, 12, 16 layers trainable, we found that 9 gives us the highest accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d66620b-aed7-4584-befd-850415381c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the last 9 layers to be trainable gives us the highest accuracy after around 20 trials using 1, 3, 6, 9, 12, and 16.\n",
    "for i in range(1,len(new_model.layers)-9):\n",
    "    new_model.layers[i].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a8f275-a3be-4174-b883-060948a587a4",
   "metadata": {},
   "source": [
    "Notice that the output layer of ResNet50 has dimension 1000, which doesn' match the number of output classes in our dataset. Thus, we add an additional dense layer with dimension 101. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77477f29-f90f-4584-a853-c7e44383cf80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 1000)              25630440  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 101)               101101    \n",
      "=================================================================\n",
      "Total params: 25,731,541\n",
      "Trainable params: 5,565,653\n",
      "Non-trainable params: 20,165,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "output_layer = tf.keras.layers.Dense(101, activation = 'softmax')\n",
    "model_res = tf.keras.Sequential([new_model, output_layer])\n",
    "model_res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc98e35-33ca-403a-8fb5-4e3f3a54551f",
   "metadata": {},
   "source": [
    "Step 3: Train the model and Evaluate the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e76a1b5f-1ced-459c-980c-c38e799a9041",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82061402-ed45-43fc-948b-9798490bbf0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "9716/9716 [==============================] - 143s 14ms/step - loss: 3.6357 - acc: 0.0865\n",
      "Epoch 2/15\n",
      "9716/9716 [==============================] - 138s 14ms/step - loss: 2.9535 - acc: 0.1751\n",
      "Epoch 3/15\n",
      "9716/9716 [==============================] - 138s 14ms/step - loss: 2.3520 - acc: 0.3770\n",
      "Epoch 4/15\n",
      "9716/9716 [==============================] - 139s 14ms/step - loss: 1.7436 - acc: 0.5797\n",
      "Epoch 5/15\n",
      "9716/9716 [==============================] - 136s 14ms/step - loss: 1.3134 - acc: 0.6987\n",
      "Epoch 6/15\n",
      "9716/9716 [==============================] - 136s 14ms/step - loss: 1.0327 - acc: 0.7610\n",
      "Epoch 7/15\n",
      "9716/9716 [==============================] - 136s 14ms/step - loss: 0.8529 - acc: 0.7963\n",
      "Epoch 8/15\n",
      "9716/9716 [==============================] - 137s 14ms/step - loss: 0.7301 - acc: 0.8206\n",
      "Epoch 9/15\n",
      "9716/9716 [==============================] - 136s 14ms/step - loss: 0.6405 - acc: 0.8402\n",
      "Epoch 10/15\n",
      "9716/9716 [==============================] - 137s 14ms/step - loss: 0.5751 - acc: 0.8540\n",
      "Epoch 11/15\n",
      "9716/9716 [==============================] - 136s 14ms/step - loss: 0.5213 - acc: 0.8663\n",
      "Epoch 12/15\n",
      "9716/9716 [==============================] - 136s 14ms/step - loss: 0.4797 - acc: 0.8763\n",
      "Epoch 13/15\n",
      "9716/9716 [==============================] - 136s 14ms/step - loss: 0.4443 - acc: 0.8835\n",
      "Epoch 14/15\n",
      "9716/9716 [==============================] - 136s 14ms/step - loss: 0.4134 - acc: 0.8920\n",
      "Epoch 15/15\n",
      "9716/9716 [==============================] - 136s 14ms/step - loss: 0.3893 - acc: 0.8969\n"
     ]
    }
   ],
   "source": [
    "history_resnet = model_res.fit(train_image_tensor, train_label_tensor, batch_size=32, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3680594-4b75-4c3d-958e-efa969d28763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5499/5499 [==============================] - 68s 12ms/step - loss: 2.2178 - acc: 0.5601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2178432941436768, 0.5601018071174622]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_res.evaluate(test_image_tensor, test_label_tensor, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc0c2501-22c2-4602-9ba8-2a660939b6b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_train = history_resnet.history['loss']\n",
    "plt.plot(loss_train, 'g', label='Training loss')\n",
    "plt.title('ResNet Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig(\"train_loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a886fbde-96b9-4e50-876d-13f1a5793931",
   "metadata": {},
   "source": [
    "Comments: \n",
    "* Contradictory to our expectation, using the pre-trained ResNet50 model still has over-fitting problems even we have tried more than 30 rounds of trials and tests, with test accuracy lower than 60%. \n",
    "* In general, the ResNet50 takes far more time to train with lower test accuracy compared to the dense network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359dd266-934f-482a-9b40-6d3053496234",
   "metadata": {},
   "source": [
    "# Conclusion: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0ded90-d2d5-4efa-94c2-57645e6ae38b",
   "metadata": {},
   "source": [
    "Through group discussion, we think training a dense network on unflattened images is a better choice for our Mathematical Expression Dataset extracted from the CROHME data based on the following reasons: \n",
    "* The Mathematical Expression Dataset we built has more than 0.3 million datapoints with balanced data. The dataset is large enough to train a model from scratch. \n",
    "* The images in our dataset are in graycale with low dimension (28x28). We believe the ResNet50 Model (224x224) will have better performance on image datasets with higher input dimension. \n",
    "* With OCR for mathematical expressions, we can transfer the mathematical expressions to latex codes, which is convenient for both students studying math and mathematicians since typing the latex codes by hand from paper drafts is boring and tiring. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0573e25-138a-40ec-94d3-161b7b00f905",
   "metadata": {},
   "source": [
    "# Installation Code saved in this section: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7474468-ca25-413f-9c68-3f17ea8e87c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "* ls(\"/home/DAVIDSON/mawang1/Workspace/CSC381/implementation-project-dl-f22-hueynataliemaureenilina/\")\n",
    "* path_zip = '/home/DAVIDSON/mawang1/Workspace/CSC381/implementation-project-dl-f22-hueynataliemaureenilina/'\n",
    "* import zipfile\n",
    "with zipfile.ZipFile('CROHME_full_v2.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(path_zip)\n",
    "* !pip install scikit-image\n",
    "* !pip install opencv-python\n",
    "* Command Line Argument: -b [BOX_SIZE] -d [DATASET_VERSION] -c [CATEGORY] -t [THICKNESS]\n",
    "* image1 = tf.keras.preprocessing.image.load_img('out.png')\n",
    "* print(skimage.__version__)\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34694b48-e851-47a8-9874-3e93e8639fd7",
   "metadata": {},
   "source": [
    "# Citation: \n",
    "* (1) Dataset Explanation: https://www.cs.rit.edu/~dprl/old/CROHMELib_LgEval_Doc.html\n",
    "* (2) Dataset Official Web Page: http://www.iapr-tc11.org/mediawiki/index.php?title=CROHME:_Competition_on_Recognition_of_Online_Handwritten_Mathematical_Expressions\n",
    "* (3) OCR Academic Paper: https://arxiv.org/pdf/1906.01969.pdf\n",
    "* (4) OCR using Tensorflow: https://medium.com/analytics-vidhya/optical-character-recognition-using-tensorflow-533061285dd3\n",
    "* (5) Python Program for Extracting Data: https://github.com/ThomasLech/CROHME_extractor\n",
    "* (6) ResNet Academic Paper: https://arxiv.org/abs/1512.03385\n",
    "* (7) ResNet50 Tensorflow: https://towardsdatascience.com/understand-and-implement-resnet-50-with-tensorflow-2-0-1190b9b52691"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow +GPU",
   "language": "python",
   "name": "python3-tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
